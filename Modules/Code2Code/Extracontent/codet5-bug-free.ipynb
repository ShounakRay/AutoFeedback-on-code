{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "8oDdbq1aaSUh",
        "outputId": "c9a950e1-83c7-4901-a68f-972fab4126e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from code_snippet_dataset import CodeSnippetDataset\n",
        "\n",
        "ds = CodeSnippetDataset(languages=[\"Python\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data we get from clustering algorithm\n",
        "raw_clusters = {\n",
        "  \"intent1\": [\"ithinksw/philo_philo/models/fields/__init__.py_0\", \"ithinksw/philo_philo/models/fields/__init__.py_1\", \"ithinksw/philo_philo/models/fields/__init__.py_2\", \"ithinksw/philo_philo/models/fields/__init__.py_3\"],\n",
        "  \"intent2\": [\"nficano/python-lambda_aws_lambda/aws_lambda.py_3\", \"nficano/python-lambda_aws_lambda/aws_lambda.py_4\", \"nficano/python-lambda_aws_lambda/aws_lambda.py_5\", \"nficano/python-lambda_aws_lambda/aws_lambda.py_6\"] \n",
        "}\n",
        "\n",
        "code_reference = {\n",
        "    \"ithinksw/philo_philo/models/fields/__init__.py_0\": {\n",
        "      \"code\": \"def __init__(self, allow=None, disallow=None, secure=True, *args, **kwargs):\\n\\t\\tsuper(TemplateField, self).__init__(*args, **kwargs)\\n\\t\\tself.validators.append(TemplateValidator(allow, disallow, secure))\",\n",
        "      \"documentation\": \"Add TemplateValidator to the list of validators .\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 30,\n",
        "        \"num_forks\": 10,\n",
        "        \"num_watchers\": 10,\n",
        "        \"num_open_issues\": 3,\n",
        "        \"created_at\": 1274327279.0\n",
        "      }\n",
        "    },\n",
        "    \"ithinksw/philo_philo/models/fields/__init__.py_1\": {\n",
        "      \"code\": \"def __init__(self, field):\\n\\t\\tself.field = field\",\n",
        "      \"documentation\": \"Shortcut to set field to field\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 50,\n",
        "        \"num_forks\": 12,\n",
        "        \"num_watchers\": 50,\n",
        "        \"num_open_issues\": 3,\n",
        "        \"created_at\": 1274327279.0\n",
        "      }\n",
        "    },\n",
        "    \"ithinksw/philo_philo/models/fields/__init__.py_2\": {\n",
        "      \"code\": \"def __get__(self, instance, owner):\\n\\t\\tif instance is None:\\n\\t\\t\\traise AttributeError # ?\",\n",
        "      \"documentation\": \"Implement the default get method for the abstract method which raises AttributeError #\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 100,\n",
        "        \"num_forks\": 12,\n",
        "        \"num_watchers\": 50,\n",
        "        \"num_open_issues\": 3,\n",
        "        \"created_at\": 1274327279.0\n",
        "      }\n",
        "    },\n",
        "    \"ithinksw/philo_philo/models/fields/__init__.py_3\": {\n",
        "      \"code\": \"def __set__(self, instance, value):\\n\\t\\tinstance.__dict__[self.field.name] = value\\n\\t\\tsetattr(instance, self.field.attname, json.dumps(value))\",\n",
        "      \"documentation\": \"Set the value of the field on the instance\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 120,\n",
        "        \"num_forks\": 12,\n",
        "        \"num_watchers\": 50,\n",
        "        \"num_open_issues\": 3,\n",
        "        \"created_at\": 1274327279.0\n",
        "      }\n",
        "    },\n",
        "    \"nficano/python-lambda_aws_lambda/aws_lambda.py_3\": {\n",
        "      \"code\": \"def upload(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\\\"config.yaml\\\",\\n    profile_name=None,\",\n",
        "      \"documentation\": \"Uploads a new project to PyPI using the specified requirements and local package name .\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 500,\n",
        "        \"num_forks\": 2,\n",
        "        \"num_watchers\": 2,\n",
        "        \"num_open_issues\": 1,\n",
        "        \"created_at\": 1677473915.0\n",
        "      }\n",
        "    },\n",
        "    \"nficano/python-lambda_aws_lambda/aws_lambda.py_4\": {\n",
        "      \"code\": \"def invoke(\\n    src,\\n    event_file=\\\"event.json\\\",\\n    config_file=\\\"config.yaml\\\",\\n    profile_name=None,\\n    verbose=False,\",\n",
        "      \"documentation\": \"Invoke the hook\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 5,\n",
        "        \"num_forks\": 0,\n",
        "        \"num_watchers\": 0,\n",
        "        \"num_open_issues\": 1,\n",
        "        \"created_at\": 1677473915.0\n",
        "      }\n",
        "    },\n",
        "    \"nficano/python-lambda_aws_lambda/aws_lambda.py_5\": {\n",
        "      \"code\": \"def init(src, minimal=False):\\n    \\\"\\\"\\\"Copies template files to a given directory.\\n\\n    :param str src:\\n        The path to output the template lambda project files.\\n    :param bool minimal:\\n        Minimal possible template files (excludes event.json).\\n    \\\"\\\"\\\"\\n\\n    templates_path = os.path.join(\\n        os.path.dirname(os.path.abspath(__file__)), \\\"project_templates\\\",\\n    )\\n    for filename in os.listdir(templates_path):\\n        if (minimal and filename == \\\"event.json\\\") or filename.endswith(\\\".pyc\\\"):\\n            continue\\n        dest_path = os.path.join(templates_path, filename)\\n\\n        if not os.path.isdir(dest_path):\\n            copy(dest_path, src)\",\n",
        "      \"documentation\": \"Copies template files to a given directory .\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 10,\n",
        "        \"num_forks\": 0,\n",
        "        \"num_watchers\": 2,\n",
        "        \"num_open_issues\": 0,\n",
        "        \"created_at\": 1677473915.0\n",
        "      }\n",
        "    },\n",
        "    \"nficano/python-lambda_aws_lambda/aws_lambda.py_6\": {\n",
        "      \"code\": \"def get_callable_handler_function(src, handler):\\n    \\\"\\\"\\\"Translate a string of the form \\\"module.function\\\" into a callable\\n    function.\\n\\n    :param str src:\\n      The path to your Lambda project containing a valid handler file.\\n    :param str handler:\\n      A dot delimited string representing the `<module>.<function name>`.\\n    \\\"\\\"\\\"\\n\\n    # \\\"cd\\\" into `src` directory.\\n    os.chdir(src)\\n\\n    module_name, function_name = handler.split(\\\".\\\")\\n    filename = get_handler_filename(handler)\\n\\n    path_to_module_file = os.path.join(src, filename)\\n    module = load_source(module_name, path_to_module_file)\\n    return getattr(module, function_name)\",\n",
        "      \"documentation\": \"Translate a string of the form module . function . into a callable function .\",\n",
        "      \"reputation\": {\n",
        "        \"num_stars\": 100,\n",
        "        \"num_forks\": 0,\n",
        "        \"num_watchers\": 3,\n",
        "        \"num_open_issues\": 0,\n",
        "        \"created_at\": 1677473915.0\n",
        "      }\n",
        "    },\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clusters that are classified based on good code and bad code \n",
        "classified_clusters = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_reputation_score(code_snippet):\n",
        "    features = code_snippet[\"reputation\"]\n",
        "    return features[\"num_stars\"] + features[\"num_forks\"] + features[\"num_watchers\"] - features[\"num_open_issues\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import ceil, floor\n",
        "for intent_category in raw_clusters:\n",
        "    intents = raw_clusters[intent_category]\n",
        "    sorted_intents = sorted(intents, reverse=True, key = lambda intent: compute_reputation_score(code_reference[intent]))\n",
        "    classified_clusters[intent_category] = (sorted_intents[:ceil(len(intents) / 2)], sorted_intents[floor(len(intents) / 2):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intent1': (['ithinksw/philo_philo/models/fields/__init__.py_3', 'ithinksw/philo_philo/models/fields/__init__.py_2'], ['ithinksw/philo_philo/models/fields/__init__.py_1', 'ithinksw/philo_philo/models/fields/__init__.py_0']), 'intent2': (['nficano/python-lambda_aws_lambda/aws_lambda.py_3', 'nficano/python-lambda_aws_lambda/aws_lambda.py_6'], ['nficano/python-lambda_aws_lambda/aws_lambda.py_5', 'nficano/python-lambda_aws_lambda/aws_lambda.py_4'])}\n"
          ]
        }
      ],
      "source": [
        "print(classified_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ithinksw/philo_philo/models/fields/__init__.py_3', 'ithinksw/philo_philo/models/fields/__init__.py_2', 'nficano/python-lambda_aws_lambda/aws_lambda.py_3', 'nficano/python-lambda_aws_lambda/aws_lambda.py_6']\n",
            "['ithinksw/philo_philo/models/fields/__init__.py_1', 'ithinksw/philo_philo/models/fields/__init__.py_0', 'nficano/python-lambda_aws_lambda/aws_lambda.py_5', 'nficano/python-lambda_aws_lambda/aws_lambda.py_4']\n"
          ]
        }
      ],
      "source": [
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for intent in classified_clusters.keys():\n",
        "    code_ids = classified_clusters[intent]\n",
        "\n",
        "    for bad_code_id in code_ids[1]:\n",
        "        inputs.append(code_reference[bad_code_id]['code'])\n",
        "    \n",
        "    for good_code_id in code_ids[0]:\n",
        "        outputs.append(code_reference[good_code_id]['code'])\n",
        "\n",
        "print(inputs)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyE10IAaaSUi"
      },
      "outputs": [],
      "source": [
        "target_function = \"def hello():\\n   print('hello world!')\"\n",
        "dicty = dict();\n",
        "dicty[\"input\"] = []\n",
        "dicty[\"target\"] = []\n",
        "counter = 0\n",
        "for example in ds.dataset:\n",
        "    if len(example[\"functions\"]) > 0:\n",
        "        dicty[\"input\"].append(example[\"functions\"][0])\n",
        "        dicty[\"target\"].append(target_function)\n",
        "        counter += 1\n",
        "    if counter == 100:\n",
        "        break\n",
        "\n",
        "\n",
        "print(dicty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBTMkMwhaSUi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_dict(dicty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udk8fF2NaSUi"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"dummy.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owX1fzytaSUj",
        "outputId": "8f87cdae-c4e4-4c20-df71-10a27666aa05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from datasets) (6.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=6.0.0\n",
            "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.22.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, regex, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, responses, pandas, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 fsspec-2023.1.0 huggingface-hub-0.12.1 multidict-6.0.4 multiprocess-0.70.14 pandas-1.5.3 pyarrow-11.0.0 regex-2022.10.31 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.1 xxhash-3.2.0 yarl-1.8.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 1.30k/1.30k [00:00<00:00, 1.33MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100%|██████████| 511k/511k [00:00<00:00, 1.46MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100%|██████████| 294k/294k [00:00<00:00, 916kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.37M/1.37M [00:00<00:00, 2.84MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 11.3k/11.3k [00:00<00:00, 11.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets transformers evaluate\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-large\")\n",
        "\n",
        "prefix = \"refine: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[\"input\"]]\n",
        "    outputs = [example for example in examples[\"target\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=outputs, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "866089ce0c4b49d0a4fef8080db5a76b",
            "89f5c33eace140abb5e2c9e47841c4a5",
            "c5a67ae68bcc4dd5bb1f4bc22aed501e",
            "797218ce645d483d945263eae94f664d",
            "8084d0361c4f4f748d32a31c19bcdb49",
            "53a0dcf2c539481db657eb7870a88d4a",
            "6b114e70ed474518ac3253b9b07a6646",
            "5934ef50ad674f15a906f56ee0dd1b64",
            "39fed73f0c9847b59174b585b61b0163",
            "c5c287854de04bb996d5f3110a5fcefd",
            "f9d89f9239ce47b08aaf93314ef1f845"
          ]
        },
        "id": "b5Sjb0pfaSUj",
        "outputId": "0ca52a6f-3924-4938-b402-10bdb2df59d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"dummy.csv\")\n",
        "min_ds = Dataset.from_pandas(df)\n",
        "tokenized_code = min_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3JP5A6uRdpdr"
      },
      "outputs": [],
      "source": [
        "tokenized_code = tokenized_code.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEtZmhtxdEUs",
        "outputId": "8af35542-c37a-457b-a012-45008b86b496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting lxml\n",
            "  Downloading lxml-4.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.22.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2022.10.31)\n",
            "Installing collected packages: tabulate, portalocker, lxml, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 lxml-4.9.2 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9K-WIb7haSUk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 8.15k/8.15k [00:00<00:00, 8.91MB/s]\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Jma0FLOfaSUk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "2c6e30ebf566430b9842b9791ad70ee6",
            "3491016eaa804c3f8483998ac567bd08",
            "79a2ecf232d849f89c77ac48593d05e7",
            "2ed6edbd84ea413b9e46f9e6f564610d",
            "7bdd2042fac1465b87dd8bb10e547153",
            "69b1aa6e3d434d00bc1ec78f97257c52",
            "4359b86b0a81470ba03a5e1639f5129e",
            "0f5f758fb8244db2a6b1b9ed5ff7b547",
            "640e9180a5b94fefbeafac3dfa192410",
            "8fd0421284d0471b980635c39f68589a",
            "fdda633b6efb4edca5a69f45e0d309d7",
            "5e3615f114a44bf9a63ef6af6bfed1f9",
            "2b7a4ec8be9346c2a09be5e586f86fe6",
            "7aaf051daf7341de84678d72d297330b",
            "608a3179ed934537bb7952375998cc6e",
            "9d7bb8be8c7c477581acbfa2df710062",
            "c4821c80e0424e7aa36742d82867f04c"
          ]
        },
        "id": "-zCf59qPaSUl",
        "outputId": "26483000-8648-4684-d571-9c590368e543"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae2b503efdd34ddabd1e8cb0fba73a3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keZZj1QufCOm",
        "outputId": "7ef5f3ea-e1cd-401b-b6bf-f3914255bc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Feb 27 20:22:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    30W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "cHWj_DgvaSUl",
        "outputId": "b531b0c0-d9d9-493b-8826-04292dcb44bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 29:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10000, training_loss=0.004881240275927121, metrics={'train_runtime': 1780.6424, 'train_samples_per_second': 89.855, 'train_steps_per_second': 5.616, 'total_flos': 2.435439545597952e+16, 'train_loss': 0.004881240275927121, 'epoch': 2.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"dummy_code_to_code_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=2,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_code[\"train\"],\n",
        "    eval_dataset=tokenized_code[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32866004556b455e884c7404048bf18e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zuzt2G0LdZsp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--michaelnath--dummy_code_to_code_model/snapshots/c4d18d605090886ac42a3905514cd3e301cd179e/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"Salesforce/codet5-base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"bos_token_id\": 1,\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32100\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--michaelnath--dummy_code_to_code_model/snapshots/c4d18d605090886ac42a3905514cd3e301cd179e/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at michaelnath/dummy_code_to_code_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--michaelnath--dummy_code_to_code_model/snapshots/c4d18d605090886ac42a3905514cd3e301cd179e/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Downloading (…)olve/main/vocab.json: 100%|██████████| 703k/703k [00:00<00:00, 1.90MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100%|██████████| 294k/294k [00:00<00:00, 1.02MB/s]\n",
            "Downloading (…)in/added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 2.32kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 12.5k/12.5k [00:00<00:00, 9.20MB/s]\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 1.48k/1.48k [00:00<00:00, 1.33MB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c/merges.txt\n",
            "loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c/added_tokens.json\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c/tokenizer_config.json\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:885: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
            "  warnings.warn(\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 300,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': \"def hello():\\n   print('hello world!')\"}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline, T5ForConditionalGeneration, RobertaTokenizer\n",
        "text = \"refine: def a(): return 1\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"michaelnath/dummy_code_to_code_model\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
        "translator(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in dummy_code_to_code_model/config.json\n",
            "Configuration saved in dummy_code_to_code_model/generation_config.json\n",
            "Model weights saved in dummy_code_to_code_model/pytorch_model.bin\n",
            "Uploading the following files to michaelnath/dummy_code_to_code_model: config.json,generation_config.json,pytorch_model.bin\n",
            "pytorch_model.bin: 100%|██████████| 892M/892M [00:34<00:00, 26.2MB/s]\n",
            "Upload 1 LFS files: 100%|██████████| 1/1 [00:34<00:00, 34.05s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/michaelnath/dummy_code_to_code_model/commit/c4d18d605090886ac42a3905514cd3e301cd179e', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='c4d18d605090886ac42a3905514cd3e301cd179e', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.push_to_hub(\"dummy_code_to_code_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f5f758fb8244db2a6b1b9ed5ff7b547": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7a4ec8be9346c2a09be5e586f86fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c6e30ebf566430b9842b9791ad70ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3491016eaa804c3f8483998ac567bd08",
              "IPY_MODEL_79a2ecf232d849f89c77ac48593d05e7",
              "IPY_MODEL_2ed6edbd84ea413b9e46f9e6f564610d",
              "IPY_MODEL_7bdd2042fac1465b87dd8bb10e547153",
              "IPY_MODEL_69b1aa6e3d434d00bc1ec78f97257c52"
            ],
            "layout": "IPY_MODEL_4359b86b0a81470ba03a5e1639f5129e"
          }
        },
        "2ed6edbd84ea413b9e46f9e6f564610d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5e3615f114a44bf9a63ef6af6bfed1f9",
            "style": "IPY_MODEL_2b7a4ec8be9346c2a09be5e586f86fe6",
            "value": true
          }
        },
        "3491016eaa804c3f8483998ac567bd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5f758fb8244db2a6b1b9ed5ff7b547",
            "placeholder": "​",
            "style": "IPY_MODEL_640e9180a5b94fefbeafac3dfa192410",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "39fed73f0c9847b59174b585b61b0163": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4359b86b0a81470ba03a5e1639f5129e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "53a0dcf2c539481db657eb7870a88d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5934ef50ad674f15a906f56ee0dd1b64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e3615f114a44bf9a63ef6af6bfed1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608a3179ed934537bb7952375998cc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "640e9180a5b94fefbeafac3dfa192410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b1aa6e3d434d00bc1ec78f97257c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7bb8be8c7c477581acbfa2df710062",
            "placeholder": "​",
            "style": "IPY_MODEL_c4821c80e0424e7aa36742d82867f04c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "6b114e70ed474518ac3253b9b07a6646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "797218ce645d483d945263eae94f664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c287854de04bb996d5f3110a5fcefd",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d89f9239ce47b08aaf93314ef1f845",
            "value": " 100000/100000 [01:02&lt;00:00, 1685.60 examples/s]"
          }
        },
        "79a2ecf232d849f89c77ac48593d05e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8fd0421284d0471b980635c39f68589a",
            "placeholder": "​",
            "style": "IPY_MODEL_fdda633b6efb4edca5a69f45e0d309d7",
            "value": ""
          }
        },
        "7aaf051daf7341de84678d72d297330b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdd2042fac1465b87dd8bb10e547153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7aaf051daf7341de84678d72d297330b",
            "style": "IPY_MODEL_608a3179ed934537bb7952375998cc6e",
            "tooltip": ""
          }
        },
        "8084d0361c4f4f748d32a31c19bcdb49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "866089ce0c4b49d0a4fef8080db5a76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f5c33eace140abb5e2c9e47841c4a5",
              "IPY_MODEL_c5a67ae68bcc4dd5bb1f4bc22aed501e",
              "IPY_MODEL_797218ce645d483d945263eae94f664d"
            ],
            "layout": "IPY_MODEL_8084d0361c4f4f748d32a31c19bcdb49"
          }
        },
        "89f5c33eace140abb5e2c9e47841c4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a0dcf2c539481db657eb7870a88d4a",
            "placeholder": "​",
            "style": "IPY_MODEL_6b114e70ed474518ac3253b9b07a6646",
            "value": "Map: 100%"
          }
        },
        "8fd0421284d0471b980635c39f68589a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7bb8be8c7c477581acbfa2df710062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4821c80e0424e7aa36742d82867f04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5a67ae68bcc4dd5bb1f4bc22aed501e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5934ef50ad674f15a906f56ee0dd1b64",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39fed73f0c9847b59174b585b61b0163",
            "value": 100000
          }
        },
        "c5c287854de04bb996d5f3110a5fcefd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d89f9239ce47b08aaf93314ef1f845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdda633b6efb4edca5a69f45e0d309d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
